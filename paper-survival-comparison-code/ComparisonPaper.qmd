---
title: "Survivalanalysis using probabilistic models"
format: 
  html: default
  md: 
    variant: gfm
    preserve-tabs: true
    wrap: preserve
    fig-width: 10
    fig-height: 6
editor: visual
execute: 
  echo: true
  warning: false
  message: false
---

```{r setup, include=FALSE}
dir.create("figures", showWarnings = FALSE)
knitr::opts_chunk$set(fig.path = "figures/")
```

Libararies

```{r, warning=FALSE}
# Packages
library(tidyverse)
library(brms)
library(tidybayes)
library(ggplot2)
library(TreeSummarizedExperiment)
library(SingleCellExperiment)
library(posterior)
library(dplyr)
library(tidyr)
library(stringr)
library(survival)
library(survminer)
library(vegan)
library(mia)
library(bayesboot)
library(IDPSurvival)
library(Matrix)
library(patchwork)
library(pROC)
library(RColorBrewer) 
library(cmdstanr)
library(ranger)
library(fastshap)
library(timeROC)
library(xgboost)
library(matrixStats)
library(catboost)
library(reticulate)

# Load funcs
source("Funcs_cleaned.R")
```

Load models and combine

```{r}
out_dir <- file.path("model_result", "shap_outputs")

# CoxNet
coxnet_metrics    <- readRDS(file.path(out_dir, "coxnet_metrics.rds"))
coxnet_shap_agg   <- readRDS(file.path(out_dir, "coxnet_shap_agg.rds"))
coxnet_shap_long  <- readRDS(file.path(out_dir, "coxnet_shap_long.rds"))
coxnet_foldC      <- readRDS(file.path(out_dir, "coxnet_foldC.rds"))

# RSF
rsf_metrics    <- readRDS(file.path(out_dir, "rsf_metrics.rds"))
rsf_shap_agg   <- readRDS(file.path(out_dir, "rsf_shap_agg.rds"))
rsf_shap_long  <- readRDS(file.path(out_dir, "rsf_shap_long.rds"))
rsf_foldC      <- readRDS(file.path(out_dir, "rsf_foldC.rds"))

# Logistic
logit_metrics   <- readRDS(file.path(out_dir, "logit_metrics.rds"))
logit_shap_agg  <- readRDS(file.path(out_dir, "logit_shap_agg.rds"))
logit_shap_long <- readRDS(file.path(out_dir, "logit_shap_long.rds"))
logit_foldC     <- readRDS(file.path(out_dir, "logit_foldC.rds"))

# CatBoost
cb_metrics    <- readRDS(file.path(out_dir, "cb_metrics.rds"))
cb_shap_agg   <- readRDS(file.path(out_dir, "cb_shap_agg.rds"))
cb_shap_long  <- readRDS(file.path(out_dir, "cb_shap_long.rds"))
cb_foldC      <- readRDS(file.path(out_dir, "cb_foldC.rds"))

# DeepSurv
deepsurv_metrics   <- readRDS(file.path(out_dir, "deepsurv_metrics.rds"))
deepsurv_shap_agg  <- readRDS(file.path(out_dir, "deepsurv_shap_agg.rds"))
deepsurv_shap_long <- readRDS(file.path(out_dir, "deepsurv_shap_long.rds"))
deepsurv_foldC     <- readRDS(file.path(out_dir, "deepsurv_foldC.rds"))

# XGBoost Cox
xgb_metrics    <- readRDS(file.path(out_dir, "xgb_metrics.rds"))
xgb_shap_agg   <- readRDS(file.path(out_dir, "xgb_shap_agg.rds"))
xgb_shap_long  <- readRDS(file.path(out_dir, "xgb_shap_long.rds"))
xgb_foldC      <- readRDS(file.path(out_dir, "xgb_foldC.rds"))

# TabPFN
tabpfn_metrics   <- readRDS(file.path(out_dir, "tabpfn_metrics.rds"))
tabpfn_shap_agg  <- readRDS(file.path(out_dir, "tabpfn_shap_agg.rds"))
tabpfn_shap_long <- readRDS(file.path(out_dir, "tabpfn_shap_long.rds"))
tabpfn_foldC     <- readRDS(file.path(out_dir, "tabpfn_foldC.rds"))

# PERMANOVA
permanova_metrics    <- readRDS(file.path(out_dir, "permanova_metrics.rds"))
permanova_foldR2     <- readRDS(file.path(out_dir, "permanova_foldR2.rds"))
permanova_shap_agg   <- readRDS(file.path(out_dir, "permanova_shap_agg.rds"))
permanova_shap_long  <- readRDS(file.path(out_dir, "permanova_shap_long.rds"))

# Combine overall metrics
metrics_all <- dplyr::bind_rows(
  coxnet_metrics, rsf_metrics, logit_metrics,
  cb_metrics, deepsurv_metrics, xgb_metrics, tabpfn_metrics,
  permanova_metrics
)

# Combine fold-wise C only
# PERMANOVA folds kept separate (used for R^2)
# permanova_foldR2
foldC_all <- dplyr::bind_rows(
  coxnet_foldC, rsf_foldC, logit_foldC,
  cb_foldC, deepsurv_foldC, xgb_foldC, tabpfn_foldC
)

# Combine SHAP (long/agg) across all models
shap_long_all <- dplyr::bind_rows(
  coxnet_shap_long, rsf_shap_long, logit_shap_long,
  cb_shap_long, deepsurv_shap_long, xgb_shap_long, tabpfn_shap_long,
  permanova_shap_long
)

shap_agg_all <- dplyr::bind_rows(
  coxnet_shap_agg, rsf_shap_agg, logit_shap_agg,
  cb_shap_agg, deepsurv_shap_agg, xgb_shap_agg, tabpfn_shap_agg,
  permanova_shap_agg
)


# Subsampling and truncation
coxnet_grids    <- readRDS(file.path(out_dir, "grid_coxnet.rds"))
rsf_grids       <- readRDS(file.path(out_dir, "grid_rsf.rds"))
logit_grids     <- readRDS(file.path(out_dir, "grid_logit.rds"))
catboost_grids  <- readRDS(file.path(out_dir, "grid_catboost.rds"))
tabpfn_grids    <- readRDS(file.path(out_dir, "grid_tabpfn.rds"))
deepsurv_grids  <- readRDS(file.path(out_dir, "grid_deepsurv.rds"))
xgb_grids       <- readRDS(file.path(out_dir, "grid_xgb.rds"))
permanova_grids <- readRDS(file.path(out_dir, "grid_permanova.rds"))
```



# Visualizations

## Performance across transformations


```{r fig-perf, fig.width=10, fig.height=6, dpi=300, fig.cap="Performance plot", fig.path="figures/"}
plot_df <- metrics_all %>%
  filter(metric %in% c("C","R2")) %>%
  mutate(
    method = factor(method,
                    levels = c("CoxNet","RSF","XGB_Cox","DeepSurv","Logit","CatBoost","TabPFN","PERMANOVA")
                    [c("CoxNet","RSF","XGB_Cox","DeepSurv","Logit","CatBoost","TabPFN","PERMANOVA") %in% method]
    ),
    metric_lbl = dplyr::recode(metric, C = "Harrell's C", R2 = "R²", .default = metric)
  )

# Order transformations by mean C across methods
model_order <- plot_df %>%
  filter(metric == "C") %>%
  group_by(model) %>%
  summarise(meanC = mean(estimate, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(meanC)) %>%
  pull(model)

plot_df <- plot_df %>% mutate(model = factor(model, levels = model_order))

# Plot
ggplot(plot_df, aes(x = model, y = estimate, color = method)) +
  geom_hline(
    data = dplyr::tibble(metric_lbl = "Harrell's C", y = 0.5),
    mapping = aes(yintercept = y),
    linetype = "dashed", linewidth = 0.5, alpha = 0.7
  ) +
  geom_errorbar(aes(ymin = lower, ymax = upper),
                position = position_dodge(width = 0.6), width = 0.15, linewidth = 0.5) +
  geom_point(position = position_dodge(width = 0.6), size = 2.8, stroke = 0.2) +
  facet_grid(rows = vars(metric_lbl), scales = "free_y", switch = "y") +
  labs(
    title = "Performance across transformations (C and PERMANOVA)",
    subtitle = "Points = estimate, bars = 95% CI; transforms ordered by mean C",
    x = "Transformation", y = NULL, color = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 20, hjust = 1),
    panel.grid.minor = element_blank(),
    strip.placement = "outside",
    strip.background = element_rect(fill = NA, color = NA)
  )
```

PERMANOVA is permutation-based, so its 95% CIs reflect K-fold variability rather than an asymptotic SE. In contrast, the other models report asymptotic 95% CIs (from the concordance estimator), so the intervals aren’t directly comparable.




```{r fig-perfbox, fig.width=10, fig.height=6, dpi=300, fig.cap="Performance boxplot", fig.path="figures/"}
# Build folds for C-models
c_folds <- foldC_all %>%
  transmute(transform = model, method, fold, value = as.numeric(C), metric = "C")

# Build folds for PERMANOVA
r2_folds <- permanova_foldR2 %>%
  transmute(transform = model, method, fold, value = as.numeric(R2), metric = "R2")

# Combine
folds_all <- bind_rows(c_folds, r2_folds) %>%
  filter(is.finite(value)) %>%
  mutate(
    method_lab = ifelse(method == "PERMANOVA", "PERMANOVA (R²)", paste0(method, " (C)"))
  )

# Order models
method_order <- c("CoxNet","RSF","XGB_Cox","DeepSurv","Logit","CatBoost","TabPFN")
present_c_methods <- unique(folds_all$method[folds_all$metric == "C"])
lvl_c <- paste0(method_order[method_order %in% present_c_methods], " (C)")
lvl_all <- c(lvl_c, "PERMANOVA (R²)")
folds_all$method_lab <- factor(folds_all$method_lab, levels = lvl_all[lvl_all %in% folds_all$method_lab])

# Order transforms by median C across C-models
t_order <- c_folds %>%
  group_by(transform) %>%
  summarise(medC = median(value, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(medC)) %>% pull(transform)
folds_all$transform <- factor(folds_all$transform, levels = t_order)

# Dashed baseline only on C panels
hline_df <- folds_all %>%
  filter(metric == "C") %>%
  distinct(method_lab) %>%
  mutate(y = 0.5)

# Plot
ggplot(folds_all, aes(x = transform, y = value)) +
  geom_hline(data = hline_df, aes(yintercept = y),
             linetype = "dashed", linewidth = 0.4, alpha = 0.7) +
  geom_boxplot(outlier.shape = NA, width = 0.65) +
  geom_jitter(width = 0.15, height = 0, size = 1, alpha = 0.45) +
  facet_wrap(~ method_lab, scales = "free_y", ncol = 3) +
  labs(
    title = "Ranking performance across transformations",
    subtitle = "C-models show Harrell's C; PERMANOVA shows R². Dashed line = C = 0.5.",
    x = "Transformation", y = NULL
  ) +
  theme_bw() +
  theme(
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 30, hjust = 1),
    legend.position = "none"
  )

```


```{r fig-pairwise, fig.width=10, fig.height=6, dpi=300, fig.cap="Pairwise C-difference", fig.path="figures/"}
# Pairwise C-difference heatmap with significance stars (p ≤ 0.05)
# - x: transform, y: transform
# - fill: mean ΔC (row − column) across CV folds
# - star: Wilcoxon signed-rank p ≤ 0.05
# - panel: model

# Fold-level C (excluded PERMANOVA)
c_folds <- foldC_all %>%
  transmute(transform = model, method, fold, C = as.numeric(C)) %>%
  filter(is.finite(C)) %>%
  mutate(
    method = factor(
      method,
      levels = c("CoxNet","RSF","XGB_Cox","DeepSurv","Logit","CatBoost","TabPFN")[
        c("CoxNet","RSF","XGB_Cox","DeepSurv","Logit","CatBoost","TabPFN") %in% method
      ]
    )
  )

# Order transforms by median C across methods
t_order <- c_folds %>%
  group_by(transform) %>%
  summarise(medC = median(C, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(medC)) %>%
  pull(transform)
c_folds <- c_folds %>% mutate(transform = factor(transform, levels = t_order))

# All pairwise (t1, t2)
pairs_long <- c_folds %>%
  dplyr::select(method, fold, t1 = transform, C1 = C) %>%
  dplyr::inner_join(
    c_folds %>% dplyr::select(method, fold, t2 = transform, C2 = C),
    by = c("method","fold"),
    relationship = "many-to-many"
  ) %>%
  dplyr::mutate(diff = C1 - C2)


# Mean differnece of C and Wilcoxon signed-rank
summ_pairs <- pairs_long %>%
  dplyr::filter(t1 != t2) %>%
  dplyr::group_by(method, t1, t2) %>%
  dplyr::summarise(
    mean_diff = mean(diff, na.rm = TRUE),
    p = suppressWarnings(wilcox.test(na.omit(diff), mu = 0, exact = FALSE)$p.value),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    star = ifelse(!is.na(p) & p <= 0.05, "*", "")     ### p <= 0.05
  )

# Complete grid
to_plot <- tidyr::complete(
  summ_pairs,
  method,
  t1 = factor(t_order, levels = t_order),
  t2 = factor(t_order, levels = t_order),
  fill = list(mean_diff = NA_real_, p = NA_real_, star = "")
) %>%
  mutate(
    t1 = factor(t1, levels = t_order),
    t2 = factor(t2, levels = t_order)
  )

# Plot
ggplot(to_plot, aes(x = t2, y = t1, fill = mean_diff)) +
  geom_tile() +
  geom_text(aes(label = star), size = 3) +
  scale_fill_gradient2(
    name = "\u0394C (row − col)",
    low = "steelblue", mid = "white", high = "firebrick",
    midpoint = 0, na.value = "grey95"
  ) +
  facet_wrap(~ method, ncol = 3) +
  coord_equal() +
  labs(
    title = "Heatmap of pairwise differences in Harrell's C",
    subtitle = "Cells show mean \u0394C across CV folds; star marks Wilcoxon signed-rank p \u2264 0.05",
    x = "Column transform", y = "Row transform"
  ) +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```




## Shapley heatmap

```{r fig-shap, fig.width=10, fig.height=6, dpi=300, fig.cap="Shapley heatmap", fig.path="figures/"}
# Settings
tau <- 0

coverage_tbl <- shap_long_all %>%
  group_by(model_key, transform, feature) %>%
  summarise(hit = any(abs(shap) > tau, na.rm = TRUE), .groups = "drop") %>%
  group_by(model_key, transform) %>%
  summarise(
    coverage   = mean(hit),
    n_features = dplyr::n(),
    .groups = "drop"
  )

coverage_tbl$transform <- factor(coverage_tbl$transform, levels = unique(coverage_tbl$transform))
coverage_tbl$model_key <- factor(coverage_tbl$model_key, levels = rev(unique(coverage_tbl$model_key)))

# Plot
ggplot(coverage_tbl, aes(x = transform, y = model_key, fill = coverage)) +
  geom_tile() +
  scale_fill_viridis_c(name = "Coverage", limits = c(0, 1)) +
  labs(
    title = "SHAP coverage",
    subtitle = "Coverage = proportion of features with abs(SHAP) > 0",
    x = "Transform", y = "Model"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid = element_blank())

```


With a zero importance threshold, most models flag nearly all features, XGBoost prunes the most, and Logit prunes slightly under TSS.



```{r fig-shapcor, fig.width=10, fig.height=6, dpi=300, fig.cap="Shapley correlation", fig.path="figures/"}
# ---- SHAP correlation heatmap with significance stars (p ≤ 0.05) ----
# - x: transform, y: transform
# - fill: correlation of mean |SHAP| across features (per model)
# - star: Wilcoxon signed-rank p ≤ 0.05 on feature-wise differences
# - panel: model

corr_method <- "spearman"   # "pearson" or "spearman"
alpha_star  <- 0.05

shap_agg_all <- shap_long_all %>%
  dplyr::group_by(model_key, transform, feature) %>%
  dplyr::summarise(mean_abs = mean(abs(shap), na.rm = TRUE), .groups = "drop")

# Order transforms by overall importance (sum of mean_abs across models & features)
t_order <- shap_agg_all %>%
  group_by(transform) %>%
  summarise(total_imp = sum(mean_abs, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(total_imp)) %>%
  pull(transform)

# Function: per-model pairwise transform correlations + Wilcoxon test on differences
one_model_corr <- function(df_model) {
  wide <- df_model %>%
    dplyr::select(transform, feature, mean_abs) %>%
    dplyr::mutate(
      transform = factor(transform, levels = t_order),
      feature   = factor(feature,   levels = unique(feature))
    ) %>%
    tidyr::pivot_wider(names_from = transform, values_from = mean_abs, values_fill = 0)

  M  <- as.matrix(wide[, setdiff(names(wide), "feature"), drop = FALSE])
  tr <- colnames(M)

  cor_mat <- suppressWarnings(stats::cor(M, method = corr_method, use = "pairwise.complete.obs"))

  expand.grid(t1 = tr, t2 = tr, stringsAsFactors = FALSE) %>%
    dplyr::mutate(
      cor = purrr::map2_dbl(t1, t2, ~ cor_mat[.x, .y]),
      p   = purrr::map2_dbl(t1, t2, ~ {
        d <- M[, .x] - M[, .y]
        d <- stats::na.omit(d)
        if (length(d) < 1L) NA_real_
        else suppressWarnings(stats::wilcox.test(d, mu = 0, exact = FALSE)$p.value)
      }),
      star = ifelse(!is.na(p) & p <= alpha_star & t1 != t2, "*", "")
    )
}

# Compute per-model grids
corr_all <- shap_agg_all %>%
  group_by(model_key) %>%
  group_modify(~ one_model_corr(.x)) %>%
  ungroup() %>%
  mutate(
    t1 = factor(t1, levels = t_order),
    t2 = factor(t2, levels = t_order),
    model_key = factor(
      model_key,
      levels = c("coxnet","rsf","xgb_cox","deepsurv","logit","catboost","tabpfn","permanova")[
        c("coxnet","rsf","xgb_cox","deepsurv","logit","catboost","tabpfn","permanova") %in% model_key
      ]
    )
  )

# If you want blank diagonal fill
# corr_all <- corr_all %>%
  # mutate(cor = ifelse(as.character(t1) == as.character(t2), NA_real_, cor),
         # star = ifelse(as.character(t1) == as.character(t2), "", star))

# Plot
ggplot(corr_all, aes(x = t2, y = t1, fill = cor)) +
  geom_tile() +
  geom_text(aes(label = star), size = 3) +
  scale_fill_gradient2(
    name = paste0("Correlation (", corr_method, ")"),
    low = "steelblue", mid = "white", high = "firebrick",
    midpoint = 0, limits = c(-1, 1), na.value = "grey95"
  ) +
  facet_wrap(~ model_key, ncol = 3) +
  coord_equal() +
  labs(
    title = "Feature-wise SHAP similarity across transforms",
    subtitle = paste0("Cells = correlation of mean |SHAP| vectors; star = Wilcoxon p \u2264 ", alpha_star),
    x = "Column transform", y = "Row transform"
  ) +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```




## Subsampling and truncation


```{r fig-subsample, fig.width=10, fig.height=6, dpi=300, fig.cap="Subsample performance", fig.path="figures/"}
# ---- Subsampling: performance vs. sample subset (%), per transform & model ----
# - x: sample subset (% of rows kept)
# - y: performance estimate (C for C-models; R² for PERMANOVA)
# - color: transformation
# - panel: model

model_keys <- c(
  catboost  = "catboost",
  coxnet    = "coxnet",
  deepsurv  = "deepsurv",
  logit     = "logit",
  rsf       = "rsf",
  tabpfn    = "tabpfn",
  xgb       = "xgb",
  permanova = "permanova"
)

model_levels <- c("CatBoost","CoxNet","DeepSurv","Logit","RSF","TabPFN","XGB_Cox","PERMANOVA")
pick_cols_sub <- c("model","transform","estimate","sample_pct")

metrics_sub_all <- purrr::map_dfr(names(model_keys), function(nm) {
  g <- get(paste0(nm, "_grids"), envir = .GlobalEnv)
  g$sub_metrics %>%
    select(any_of(pick_cols_sub)) %>%
    filter(is.finite(estimate), is.finite(sample_pct)) %>%
    mutate(model = factor(model, levels = model_levels))
})

p_sub <- metrics_sub_all %>%
  mutate(sample_pct = 100 * sample_pct) %>%
  arrange(model, transform, sample_pct) %>%
  ggplot(aes(x = sample_pct, y = estimate, color = transform, group = transform)) +
  geom_line(alpha = 0.7) +
  geom_point(size = 1.8) +
  facet_wrap(~ model, ncol = 3, scales = "free_y") +
  labs(
    title = "Performance vs. sample subset (subsampling)",
    x = "Sample subset (%)",
    y = "C-statistic (PERMANOVA shows R²)",
    color = "Transform"
  ) +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.minor = element_blank())

print(p_sub)
```





```{r fig-truncation, fig.width=10, fig.height=6, dpi=300, fig.cap="Truncation performance", fig.path="figures/"}
# ---- Truncation: performance vs. follow-up time, per transform & model ----
# - x: follow-up time (truncation threshold)
# - y: performance estimate (C for C-models; R² for PERMANOVA)
# - color: transformation
# - panel: model

pick_cols_tr <- c("model","transform","estimate","followup_time")

metrics_tr_all <- purrr::map_dfr(names(model_keys), function(nm) {
  g <- get(paste0(nm, "_grids"), envir = .GlobalEnv)
  g$tr_metrics %>%
    select(any_of(pick_cols_tr)) %>%
    filter(is.finite(estimate), is.finite(followup_time)) %>%
    mutate(model = factor(model, levels = model_levels))
})

p_trunc <- metrics_tr_all %>%
  arrange(model, transform, followup_time) %>%
  ggplot(aes(x = followup_time, y = estimate, color = transform, group = transform)) +
  geom_line(alpha = 0.7) +
  geom_point(size = 1.8) +
  facet_wrap(~ model, ncol = 3, scales = "free_y") +
  labs(
    title = "Performance vs. follow-up time (truncation)",
    x = "Follow-up time",
    y = "C-statistic (PERMANOVA shows R²)",
    color = "Transform"
  ) +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.minor = element_blank())

print(p_trunc)

```

