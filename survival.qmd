---
title: "Survivalanalysis using probabilistic models"
format: 
  html: default
  md: 
    variant: gfm
    preserve-tabs: true
    wrap: preserve
    fig-width: 10
    fig-height: 6
editor: visual
execute: 
  echo: true
  warning: false
  message: false
---

```{r setup, include=FALSE}
dir.create("figures", showWarnings = FALSE)
knitr::opts_chunk$set(fig.path = "figures/")
```

# Introduction

Let's download all the necessary libraries:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(ggplot2)
library(TreeSummarizedExperiment)
library(posterior)
library(dplyr)
library(tidyr)
library(stringr)
library(survival)
library(survminer)
library(vegan)
library(mia)
library(bayesboot)
library(IDPSurvival)
library(cmdstanr)
library(patchwork)
library(pROC)
library(RColorBrewer) 
library(ranger)
library(timeROC)
library(xgboost)
library(matrixStats)
library(keras)
library(tensorflow)
library(catboost)
library(reticulate)
```

## Data manipulation

All data preprocessing was carried out in a separate script (`data.R`) to ensure clarity and modularity in the analysis workflow. The script loads the raw data, applies appropriate transformations, removes invalid samples, and derives variables needed for modeling.

```{r, include=FALSE}
# Download the data preprocessing
source("funcs.R")
source("data.R")
```

## Data transformations

To evaluate the effect of different data preprocessing strategies on survival model performance, several commonly used microbial feature transformations were applied:

-   **CLR (Centered Log-Ratio)**\
    Transforms counts to log-ratios relative to the geometric mean of all features. Suitable for compositional data.

-   **rCLR (Robust CLR)**\
    A robust version of CLR that downweights outliers. Helps reduce the influence of extreme values.

-   **log-TSS (Log-transformed Total Sum Scaling)**\
    Counts are converted to relative abundances and then log-transformed to stabilize variance and reduce skewness.

-   **LRA (Log-Ratio Analysis)**\
    Computes pairwise log-ratios between features after log-transformation. Emphasizes relative differences.

-   **PA (Presence/Absence)**\
    Binary encoding of whether each taxon is detected. Ignores abundance but captures occurrence. The detection threshold for PA was relative (0.1% TSS)

-   **TSS (Total Sum Scaling)**\
    Normalizes counts to relative abundances by dividing each sample by its total count.

-   **Arcsin (Arcsin-sqrt transformation of TSS)**\
    Applies arcsin square-root transformation to relative abundances, useful for proportions near 0 or 1.

-   **ALR (Additive Log-Ratio)**\
    Computes log-ratios relative to a selected reference taxon. Sensitive to choice of reference. In this analysis reference taxon is g__Sutterella.

Each transformation highlights different aspects of the microbial composition and is evaluated independently in downstream survival models.

# Optimizing Feature Count for Survival Prediction

In this analysis, we systematically evaluate how the number of input features affects the predictive performance of Bayesian survival models. Starting from a single feature and increasing the count in powers of two up to a predefined maximum, we compare model performance using the concordance index (C-index) across multiple data transformations. The models are fit using a weakly informative normal prior for the regression coefficients, which encourages regularization while allowing flexibility. This approach helps identify a potential "sweet spot" where the model achieves high performance with a minimal and interpretable feature set, before diminishing returns or overfitting may occur.

```{r, include=FALSE}
# Load the results
res_brm_result <-readRDS(file.path("model_result", "feature_survival_result2.rds"))

# Normal-prior models
fit_clr_normal    <- readRDS(file.path("model_result", "fit_clr_normal.rds"))
fit_rclr_normal   <- readRDS(file.path("model_result", "fit_rclr_normal.rds"))
fit_logtss_normal <- readRDS(file.path("model_result", "fit_logtss_normal.rds"))
fit_lra_normal    <- readRDS(file.path("model_result", "fit_lra_normal.rds"))
fit_pa_normal     <- readRDS(file.path("model_result", "fit_pa_normal.rds"))
fit_tss_normal    <- readRDS(file.path("model_result", "fit_tss_normal.rds"))
fit_asin_normal   <- readRDS(file.path("model_result", "fit_asin_normal.rds"))
fit_alr_normal    <- readRDS(file.path("model_result", "fit_alr_normal.rds"))

# Horseshoe-prior models
fit_clr_hs    <- readRDS(file.path("model_result", "fit_clr_hs.rds"))
fit_rclr_hs   <- readRDS(file.path("model_result", "fit_rclr_hs.rds"))
fit_logtss_hs <- readRDS(file.path("model_result", "fit_logtss_hs.rds"))
fit_lra_hs    <- readRDS(file.path("model_result", "fit_lra_hs.rds"))
fit_pa_hs     <- readRDS(file.path("model_result", "fit_pa_hs.rds"))
fit_tss_hs    <- readRDS(file.path("model_result", "fit_tss_hs.rds"))
fit_asin_hs   <- readRDS(file.path("model_result", "fit_asin_hs.rds"))
fit_alr_hs    <- readRDS(file.path("model_result", "fit_alr_hs.rds"))

```

To analyze how predictive performance varies across transformations and different numbers of selected features, we reorganize the model results into a long-format data frame. This structure facilitates visualization and comparison across transformation methods and feature subset sizes. Each row represents a single model fit, annotated with the number of features used (`N`), the transformation method applied, and the number of taxa (`ntaxa`) considered in the subset.

```{r, fig.width=10, fig.height=6, dpi=300, warning=FALSE}
# Reshape results into long format
res_brm_df <- purrr::imap_dfr(res_brm_result, function(method_list, ntaxa_name) {
  ntaxa_val <- as.numeric(gsub("ntaxa_", "", ntaxa_name))
  purrr::imap_dfr(method_list, function(df, method_name) {
    df %>%
      mutate(
        ntaxa = ntaxa_val,
        method = method_name
      )
  })
})

# Visualize C-index values across transformation methods and feature counts
ggplot(res_brm_df, aes(x = N, y = C_index, color = method)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  facet_wrap(~ ntaxa, labeller = label_both, scales = "free_y") +
  labs(
    title = "C-index of Bayesian Cox models across transformation methods",
    x = "Number of selected features (N)",
    y = "C-index (posterior mean)",
    color = "Transformation"
  ) +
  scale_x_log10() +
  theme_minimal(base_size = 14)

```

Model performance, measured by the C-index, improves as more features are included but levels off around 20 features. After that, additional features offer no benefit for most of the models. This suggests that using about 20 top features is a good balance between simplicity and performance.

# Survival model

In survival analysis, Cox models are fitted using microbial features as predictors. To reduce dimensionality and avoid overfitting, the 20 most informative features are selected for each data transformation based on univariate Cox regression. This improves model performance and interpretability.

Bayesian Cox models are then fitted using brm() with two alternative priors on the coefficients: a weakly informative normal(0, 1) prior and a sparsity-inducing horseshoe prior. The modeling is implemented in model.R, and results are loaded for analysis.

Posterior hazard ratio estimates are computed and visualized only for selected transformations: log-transformed relative abundance, centered log-ratio (CLR), and log-ratio analysis (LRA). This allows clearer comparison of interpretability and the direction of feature effects.

## Relative log-abundance modeling

The log-transformed total sum scaling (log-TSS) approach is a commonly used normalization method where relative abundances are scaled and log-transformed to stabilize variance and reduce skewness. Both normal and horseshoe priors were used when fitting the Bayesian Cox models to compare how the choice of prior affects the estimated hazard ratios. This transformation makes microbial data more suitable for downstream regression modeling.

We take summaries of the models.

```{r, warning=FALSE}
# Print model summary
summary(fit_logtss_normal)
summary(fit_logtss_hs)
```

The models show good convergence diagnostics. All Rhat values are equal to 1.00, indicating that the chains have converged well. Additionally, both Bulk and Tail Effective Sample Sizes (ESS) are high across all parameters, suggesting that the posterior distributions are well estimated and the sampling was efficient.

Posterior samples of the coefficients are extracted and summarized by computing the median, 2.5%, and 97.5% quantiles, forming the 95% credible interval for each predictor. The posterior medians and credible intervals are plotted as hazard ratios. Predictors whose intervals do not cross 1 (indicating statistical relevance) are highlighted in red, and others in black. The plot is sorted by effect size.

```{r, fig.width=14, fig.height=6, dpi=300, warning=FALSE}
# Plot
p1 <- plot_top_hr(fit_logtss_normal,
                  title = "logTSS – Normal prior",
                  top_k = 20)
p2 <- plot_top_hr(fit_logtss_hs,
                  title = "logTSS – Horseshoe prior",
                  top_k = 20)
p1 + p2
```
In the logTSS-transformed models, the normal prior identified several taxa with credible intervals excluding 1, including g_Dialister (higher risk) and g_Roseburia and g_Prevotella (lower risk). Under the horseshoe prior, all coefficients were shrunk toward zero and no taxa remained significant, reflecting the stronger regularization of this prior.

## CLR-transformed modeling

In another model, we used the top microbial features based on their individual associations with the outcome. Before fitting the model, we applied a centered log-ratio (CLR) transformation to express each microbe’s level in relation to the others. Both models were fitted with different priors (normal and horseshoe) to compare the effect of prior choice on coefficient estimates. This helps make the results easier to interpret and reduces the chance of misleading correlations.

We take summaries of the models.

```{r, warning=FALSE}
# Print model summary
summary(fit_clr_normal)
summary(fit_clr_hs)
```

The models show good convergence diagnostics. All Rhat values are equal to 1.00, indicating that the chains have converged well. Additionally, both Bulk and Tail Effective Sample Sizes (ESS) are high across all parameters, suggesting that the posterior distributions are well estimated and the sampling was efficient.

The posterior medians and credible intervals are plotted as hazard ratios as earlier.

```{r, fig.width=14, fig.height=6, dpi=300, warning=FALSE}
# Plot
p1 <- plot_top_hr(fit_clr_normal,
                  title = "clr – Normal prior",
                  top_k = 20)
p2 <- plot_top_hr(fit_clr_hs,
                  title = "clr – Horseshoe prior",
                  top_k = 20)
p1 + p2
```

In the CLR-transformed models, the normal prior identified g_Roseburia, g_Lachnospira, and g_Prevotella as significantly associated with lower risk. With the horseshoe prior, all effects were shrunk toward zero and no taxa remained significant, indicating stronger regularization.


## LRA-based modeling

We also built survival models using pairwise log-ratios between selected microbial taxa. Both models were fitted with different priors (normal and horseshoe) to compare the effect of prior choice on coefficient estimates. This method focuses on the balance between microbes instead of looking at their individual levels. It helps reduce misleading associations and gives a clearer picture of how microbes relate to the outcome relative to one another.

We take summaries of the models.

```{r, warning=FALSE}
# Print model summary
summary(fit_lra_normal)
summary(fit_lra_hs)
```

The models show good convergence diagnostics. All Rhat values are equal to 1.00, indicating that the chains have converged well. Bulk and Tail Effective Sample Sizes are also high, suggesting that the posterior distributions are well estimated and sampling was efficient.

The log-ratio coefficients are plotted below as hazard ratios.

```{r, fig.width=14, fig.height=6, dpi=300, warning=FALSE}
# Plot
p1 <- plot_top_hr(fit_lra_normal,
                  title = "LRA – Normal prior",
                  top_k = 20)
p2 <- plot_top_hr(fit_lra_hs,
                  title = "LRA – Horseshoe prior",
                  top_k = 20)
p1 + p2
```

In the LRA-transformed models, the normal prior produced some wide credible intervals, likely reflecting collinearity among the log-ratio features. Only one feature (f_Peptostreptococcaceae_g_g_Streptococcus) was significant. Under the horseshoe prior, all effects were more strongly shrunk toward zero, and no features remained significant, consistent with its stronger regularization.


# Survival curves

## Kaplan-Meier curve

First classical Kaplan–Meier estimator is applied to provide a robust and interpretable nonparametric summary of cumulative mortality over time.

```{r}
# Fit Kaplan-Meier survival model
surv_fit <- survfit(Surv(Event_time, Event) ~ 1, data = df)

# Plot cumulative mortality curve
ggsurvplot(
  surv_fit,
  data = df,
  conf.int = TRUE,
  fun = "event",  
  palette = "blue",
  xlab = "Time (years)",
  ylab = "Cumulative mortality (%)",
  title = "Overall cumulative mortality"
)
```

This plot shows the overall cumulative mortality over a 10-year follow-up period. The curve represents the estimated probability of death over time in the entire cohort. The shaded area around the curve indicates the 95% confidence interval, and the small vertical ticks represent censored observations. By the end of the follow-up, cumulative mortality reaches approximately 60%, with a fairly steady increase over time.

## Probabilistic Survival Curve with IDPSurvival

We now estimate a probabilistic survival curve using the `isurvfit()` function from the `IDPSurvival` package. This method is based on the Imprecise Dirichlet Process, which provides robust survival estimates with uncertainty bounds, especially useful for small or uncertain datasets.

```{r}
# Create the Surv object
surv_obj <- Surv(time = df$Event_time, event = df$Event)

# Estimate the IDP survival curve
fit <- isurvfit(surv_obj ~ 1, data = df, s = 1, 
                conf.type = "exact", nsamples = 2000, display = FALSE)

# Plot the survival curve
plot(fit)
title("Probabilistic Survival Curve (IDP)")
mtext("Time (years)", side = 1, line = 2)
mtext("Survival probability", side = 2, line = 2)
legend('bottomleft', c("Lower expectation",
          "Upper expectation","Confidence intervals"), lty=c(1,1,2),lwd=c(1,2,1))
```

The parameter `s = 1` controls the strength of the prior. A higher `s` reflects more confidence in the prior and results in narrower uncertainty bands. Conversely, lower values of `s` allow for more imprecision, widening the interval between lower and upper expectations. The parameter `nsamples = 2000` specifies the number of posterior samples used to construct the credible intervals. A larger value gives a smoother and more stable estimate of the uncertainty region. The `conf.type = "exact"` option determines how the uncertainty bounds are calculated. When set to `"exact"`, the intervals are computed using the full posterior distribution.

## Comparison of Classical and Probabilistic Survival Estimation Methods

To better understand the differences between classical and probabilistic survival estimates, we compare the Kaplan–Meier curve with the survival curve derived from the Imprecise Dirichlet Process approach.

```{r}
# Fit the classical Kaplan–Meier survival model
km_fit <- survfit(Surv(Event_time, Event) ~ 1, data = df)

# Fit the probabilistic IDP survival model (s = 1)
idp_fit <- isurvfit(Surv(Event_time, Event) ~ 1, data = df, s = 1,
                    conf.type = "exact", nsamples = 2000, display = FALSE)

# Prepare Kaplan–Meier survival curve data
km_df <- data.frame(
  time = km_fit$time,
  surv = km_fit$surv,
  lower = km_fit$lower,
  upper = km_fit$upper,
  method = "Kaplan–Meier"
)

# Prepare IDP survival curve data using midpoint between lower and upper expectations
idp_df <- data.frame(
  time = idp_fit$time,
  surv = (idp_fit$survUP + idp_fit$survLOW) / 2,
  lower = idp_fit$lower,
  upper = idp_fit$upper,
  method = "IDP (s = 1)"
)

# Combine the datasets for plotting
combined_df <- bind_rows(km_df, idp_df)

# Plot the survival curves
ggplot(combined_df, aes(x = time, y = surv, color = method, fill = method)) +
  geom_step(linewidth = 1.2) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2, color = NA) +
  labs(
    title = "Survival Curve Comparison: Kaplan–Meier vs. IDP (s = 1)",
    x = "Time",
    y = "Survival probability",
    color = "Method",
    fill = "Method"
  ) +
  theme_minimal(base_size = 14)
```

The point estimates from the IDP and Kaplan–Meier methods are very similar, but the uncertainty band from the IDP model lies slightly lower than uncertainty band from the Kaplan-Meier.

# Comparison of transformations Using Microbial Features in Survival Analysis

To evaluate how different data transformations affect survival modeling, we compared eight preprocessing approaches:
centered log-ratio (CLR), robust CLR (rCLR), pairwise log-ratio analysis (LRA), additive log-ratio (ALR), presence/absence (PA), total sum scaling (TSS), log-transformed TSS (logTSS), and arcsin square root (ASIN).

For each transformation, we selected the 20 microbial features most strongly associated with survival time based on univariate Cox regression. This consistent feature selection ensures a fair comparison across transformations.

Bayesian Cox proportional hazards models were fitted for each transformation using two different priors on the coefficients:

- Normal(0,1) prior, representing weakly informative assumptions.

- Horseshoe prior, promoting sparsity and reducing overfitting in high-dimensional settings.

Model performance for each prior–transformation combination was evaluated using leave-one-out cross-validation (LOO) to estimate out-of-sample predictive accuracy.

```{r, include=FALSE}
# Load results
loo_normal <- readRDS(file.path("model_result", "loo_normal.rds"))
loo_comp_normal <- readRDS(file.path("model_result", "loo_compare_normal.rds"))
loo_hs <- readRDS(file.path("model_result", "loo_hs.rds"))
loo_comp_hs <- readRDS(file.path("model_result", "loo_compare_hs.rds"))

```

```{r}
# Check Pareto k diagnostics
cat("Normal prior models – Pareto k > 0.7:\n")
print(sapply(loo_normal, function(x) sum(x$diagnostics$pareto_k > 0.7)))

cat("\nHorseshoe prior models – Pareto k > 0.7:\n")
print(sapply(loo_hs, function(x) sum(x$diagnostics$pareto_k > 0.7)))

# Print LOO comparisons
cat("\nLOO comparison – Normal prior:\n")
print(loo_comp_normal)

cat("\nLOO comparison – Horseshoe prior:\n")
print(loo_comp_hs)
```

```{r, fig.width=10, fig.height=6, dpi=300}
# Create combined data frame
dff_all <- rbind(
  get_elpd_df(loo_normal, "Normal"),
  get_elpd_df(loo_hs, "Horseshoe")
)

# Keep model order consistent by average performance
model_order <- dff_all %>%
  group_by(model) %>%
  summarise(mean_elpd = mean(elpd, na.rm = TRUE)) %>%
  arrange(desc(mean_elpd)) %>%
  pull(model)

dff_all$model <- factor(dff_all$model, levels = model_order)

# Plot
ggplot(dff_all, aes(x = model, y = elpd, color = model, shape = prior)) +
  geom_point(size = 4, position = position_dodge(width = 0.5)) +
  geom_errorbar(
    aes(ymin = elpd - se, ymax = elpd + se),
    width = 0.15,
    size = 1,
    position = position_dodge(width = 0.5)
  ) +
  geom_hline(yintercept = max(dff_all$elpd), linetype = "dashed", color = "gray40") +
  scale_color_brewer(palette = "Set2") +
  labs(
    title = "Model Comparison via LOO-ELPD (Normal vs Horseshoe)",
    y = "Expected Log Predictive Density (ELPD)",
    x = "Transformation",
    shape = "Prior"
  ) +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
  )
```

After applying moment matching, all Pareto $k$ values were below the recommended threshold of $0.7$, indicating that the LOO estimates are reliable for model comparison.

Across both prior specifications, the LRA (log-ratio analysis) model achieved the highest expected log predictive density (ELPD), showing the best out-of-sample predictive performance. Under the normal prior, performance differences between transformations were more pronounced, with CLR, rCLR, logTSS. With the horseshoe prior, differences between models narrowed, but LRA remained the top performer.The detection threshold for PA was relative (0.1% TSS), and it was the only method that performed better with the normal prior than with the horseshoe prior.

This pattern suggests that the stronger regularization of the horseshoe prior reduces performance gaps between transformations. Overall, these results reinforce that transformations, particularly LRA, yield more predictive survival models in this context.

# Model Predictions vs. Known Events

We plot the predicted risk scores from all transformations under the normal prior to examine how well each model distinguishes between events and non-events, and whether higher predicted risk corresponds to shorter observed survival times. 

```{r, fig.width=10, fig.height=6, dpi=300}
# Normal prior
df_rclr_n   <- get_pred_df(fit_rclr_normal,   method_name = "rCLR")
df_clr_n    <- get_pred_df(fit_clr_normal,    method_name = "CLR")
df_logtss_n <- get_pred_df(fit_logtss_normal, method_name = "logTSS")
df_lra_n    <- get_pred_df(fit_lra_normal,    method_name = "LRA")
df_pa_n     <- get_pred_df(fit_pa_normal,     method_name = "PA")
df_tss_n    <- get_pred_df(fit_tss_normal,    method_name = "TSS")
df_asin_n   <- get_pred_df(fit_asin_normal,   method_name = "Arcsin sqrt(TSS)")
df_alr_n    <- get_pred_df(fit_alr_normal,    method_name = "ALR")

df_all_n <- dplyr::bind_rows(
  df_clr_n, df_rclr_n, df_logtss_n, df_lra_n, df_pa_n, df_tss_n, df_asin_n, df_alr_n
)

ggplot(df_all_n, aes(x = risk_score, y = Event_time, color = factor(Event))) +
  geom_point(alpha = 0.7, size = 2) +
  geom_smooth(method = "loess", se = FALSE, color = "black", span = 1) +
  scale_color_manual(values = c("0" = "#00BFC4", "1" = "#F8766D")) +
  facet_wrap(~Method, scales = "free_x") +
  labs(
    title = "Predicted Risk Score vs. Survival Time (All Transformations) – Normal prior",
    x = "Predicted Risk Score (Posterior Median)",
    y = "Observed Survival Time",
    color = "Event"
  ) +
  theme_minimal(base_size = 14)

```

The plot shows a consistent negative association between predicted risk score and survival time across most transformations. Higher risk scores are linked to shorter survival, with event cases (red) clustering toward high-risk, high-survival regions and censored cases (blue) concentrated at lower risk scores and longer survival times. The fitted trend lines reinforce this relationship, suggesting that the models capture meaningful patterns in outcome timing.

Next, we repeat the visualization for models fitted with the horseshoe prior.

```{r, fig.width=10, fig.height=6, dpi=300}
# Horseshoe prior
df_rclr_h   <- get_pred_df(fit_rclr_hs,   method_name = "rCLR")
df_clr_h    <- get_pred_df(fit_clr_hs,    method_name = "CLR")
df_logtss_h <- get_pred_df(fit_logtss_hs, method_name = "logTSS")
df_lra_h    <- get_pred_df(fit_lra_hs,    method_name = "LRA")
df_pa_h     <- get_pred_df(fit_pa_hs,     method_name = "PA")
df_tss_h    <- get_pred_df(fit_tss_hs,    method_name = "TSS")
df_asin_h   <- get_pred_df(fit_asin_hs,   method_name = "Arcsin sqrt(TSS)")
df_alr_h    <- get_pred_df(fit_alr_hs,    method_name = "ALR")

df_all_h <- dplyr::bind_rows(
  df_clr_h, df_rclr_h, df_logtss_h, df_lra_h, df_pa_h, df_tss_h, df_asin_h, df_alr_h
)

ggplot(df_all_h, aes(x = risk_score, y = Event_time, color = factor(Event))) +
  geom_point(alpha = 0.7, size = 2) +
  geom_smooth(method = "loess", se = FALSE, color = "black", span = 1) +
  scale_color_manual(values = c("0" = "#00BFC4", "1" = "#F8766D")) +
  facet_wrap(~Method, scales = "free_x") +
  labs(
    title = "Predicted Risk Score vs. Survival Time (All Transformations) – Horseshoe prior",
    x = "Predicted Risk Score (Posterior Median)",
    y = "Observed Survival Time",
    color = "Event"
  ) +
  theme_minimal(base_size = 14)

```

The overall patterns are visually very similar to those observed with the normal prior, indicating that the choice of prior has little effect on the qualitative relationship between predicted risk and survival time in this dataset.


# Posterior-based AUROC and C-index Comparison of Survival Models

We assess model discrimination with two complementary metrics computed from the posterior. First, we calculate AUROC for every posterior draw of the linear predictor against the observed events. This gives a distribution of AUROC values that naturally reflects parameter uncertainty. Second, we compute Harrell’s C-index for each draw using the observed survival times and censoring, interpreting higher scores as higher risk (earlier events). We report both metrics as posterior medians with 95% credible intervals.


```{r, fig.width=10, fig.height=6, dpi=300, warning=FALSE}
# Read RDS
auc_all <- readRDS(file.path("model_result", "posterior_auc_all.rds"))

# Summarise: median + 95% credible interval for AUROC
auc_summary <- auc_all %>%
  group_by(model, prior) %>%
  summarise(
    median_auc = median(AUROC),
    lower = quantile(AUROC, 0.025),
    upper = quantile(AUROC, 0.975),
    .groups = "drop"
  )

# Order models by mean AUROC across priors
model_order <- auc_summary %>%
  group_by(model) %>%
  summarise(mean_auc = mean(median_auc), .groups = "drop") %>%
  arrange(desc(mean_auc)) %>%
  pull(model)

auc_summary$model <- factor(auc_summary$model, levels = model_order)

# Plot
ggplot(auc_summary, aes(x = model, y = median_auc, color = model, shape = prior)) +
  geom_point(size = 4, position = position_dodge(width = 0.5)) +
  geom_errorbar(
    aes(ymin = lower, ymax = upper),
    width = 0.15,
    size = 1,
    position = position_dodge(width = 0.5)
  ) +
  geom_hline(yintercept = max(auc_summary$median_auc), linetype = "dashed", color = "gray40") +
  scale_color_brewer(palette = "Set2") +
  labs(
    title = "Model Comparison via Posterior AUROC (Normal vs Horseshoe)",
    y = "AUROC",
    x = "Transformation",
    shape = "Prior"
  ) +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
  )
```




```{r, fig.width=10, fig.height=6, dpi=300}
# Read RDS
c_all <- readRDS(file.path("model_result", "cindex_posterior_all.rds"))

# Summarise: median + 95% credible interval
c_summary <- c_all %>%
  filter(is.finite(Cindex)) %>%
  group_by(model, prior) %>%
  summarise(
    median_c = median(Cindex),
    lower    = quantile(Cindex, 0.025),
    upper    = quantile(Cindex, 0.975),
    .groups  = "drop"
  )

# Order models by average median C across priors
model_order <- c_summary %>%
  group_by(model) %>%
  summarise(mean_med = mean(median_c), .groups = "drop") %>%
  arrange(desc(mean_med)) %>%
  pull(model)

c_summary$model <- factor(c_summary$model, levels = model_order)

# Plot
ggplot(c_summary, aes(x = model, y = median_c, color = model, shape = prior)) +
  geom_point(size = 4, position = position_dodge(width = 0.5)) +
  geom_errorbar(
    aes(ymin = lower, ymax = upper),
    width = 0.15, size = 1,
    position = position_dodge(width = 0.5)
  ) +
  geom_hline(yintercept = max(c_summary$median_c), linetype = "dashed", color = "gray40") +
  scale_color_brewer(palette = "Set2") +
  labs(
    title = "Model Comparison via Posterior Harrell's C (Normal vs Horseshoe)",
    y = "Harrell's C",
    x = "Transformation",
    shape = "Prior"
  ) +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

In both the AUROC and Harrell’s C panels the story is consistent. Log-ratio-based models perform best, LRA leads, with ALR next, while CLR/rCLR are competitive but a step down. Abundance transforms (logTSS, asin) sit in the middle. PA and especially TSS are clearly weakest and show the widest uncertainty. Across priors, Normal is generally on par with or slightly ahead of Horseshoe, suggesting strong shrinkage trims some discriminative signal, the clearest Normal advantage appears for PA. The time-aware C-index corroborates the AUROC ranking.


# Kaplan–Meier curves by median risk (Normal-prior models)

For each model, we compute a risk score as the posterior median of its linear predictor and split individuals at the model-specific median into Low vs High risk. The panels show Kaplan–Meier curves with 95% CIs for each transformation. 

```{r, fig.width=10, fig.height=6, dpi=300}
# Collect risk scores from Normal-prior models
df_all_n <- dplyr::bind_rows(
  get_pred_df(fit_rclr_normal,   "rCLR"),
  get_pred_df(fit_clr_normal,    "CLR"),
  get_pred_df(fit_logtss_normal, "logTSS"),
  get_pred_df(fit_lra_normal,    "LRA"),
  get_pred_df(fit_pa_normal,     "PA"),
  get_pred_df(fit_tss_normal,    "TSS"),
  get_pred_df(fit_asin_normal,   "Arcsin sqrt(TSS)"),
  get_pred_df(fit_alr_normal,    "ALR")
)

# Median split within each model: Low vs High
df_all_n <- df_all_n %>%
  dplyr::group_by(Method) %>%
  dplyr::mutate(
    RiskGroup = if_else(risk_score >= median(risk_score, na.rm = TRUE), "High", "Low"),
    RiskGroup = factor(RiskGroup, levels = c("Low","High"))
  ) %>%
  dplyr::ungroup()

# Kaplan–Meier data per model and risk group
km_df <- df_all_n %>%
  dplyr::group_split(Method) %>%
  purrr::map_dfr(function(d){
    meth <- as.character(d$Method[1])
    sf <- survival::survfit(Surv(Event_time, Event) ~ RiskGroup, data = d,
                            conf.int = 0.95, conf.type = "log-log")
    survminer::surv_summary(sf, data = d) %>%
      dplyr::mutate(Method = meth, RiskGroup = sub("^RiskGroup=", "", strata)) %>%
      dplyr::select(Method, time, surv, lower, upper, RiskGroup)
  })

# Plot
ggplot(km_df, aes(x = time, y = surv, color = RiskGroup, fill = RiskGroup)) +
  geom_step(linewidth = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, color = NA) +
  facet_wrap(~ Method, ncol = 4) +
  labs(
    title = "Kaplan–Meier by median risk (High vs Low) — Normal prior models",
    x = "Time",
    y = "Survival probability",
    color = "Risk group",
    fill  = "Risk group"
  ) +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        panel.spacing.x = unit(0.8, "lines"))

```


The panels show clear risk separation across all Normal-prior models. The High group (red) consistently has lower survival than the Low group (blue), with gaps opening early and often widening over time. Log-ratio transforms (ALR, LRA, CLR, rCLR) perform best, logTSS and asin are close behind, and TSS is weakest. The split is model specific.

We will also repeat the analysis with a four-group split using the 25th, 50th, and 75th percentiles (Q1–Q4)


```{r, fig.width=10, fig.height=6, dpi=300}
# Quartile split (25/50/75%) within each model: Q1 (Low), Q4 (High)
df_q <- df_all_n %>%
  dplyr::group_by(Method) %>%
  dplyr::mutate(
    RiskQ = dplyr::ntile(risk_score, 4),
    RiskQ = factor(RiskQ, levels = 1:4,
                   labels = c("Q1 (Low)", "Q2", "Q3", "Q4 (High)"))
  ) %>%
  dplyr::ungroup()

# KM curves by quartile for each model
km_df_q <- df_q %>%
  dplyr::group_split(Method) %>%
  purrr::map_dfr(function(d){
    meth <- as.character(d$Method[1])
    sf <- survival::survfit(Surv(Event_time, Event) ~ RiskQ, data = d,
                            conf.int = 0.95, conf.type = "log-log")
    survminer::surv_summary(sf, data = d) %>%
      dplyr::mutate(Method = meth, RiskQ = sub("^RiskQ=", "", strata)) %>%
      dplyr::select(Method, time, surv, lower, upper, RiskQ)
  })

# Plot
ggplot(km_df_q, aes(x = time, y = surv, color = RiskQ, fill = RiskQ)) +
  geom_step(linewidth = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, color = NA) +
  facet_wrap(~ Method, ncol = 4) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette  = "Set1") +
  labs(
    title = "Kaplan–Meier by risk quartiles (Q1–Q4) — Normal prior models",
    x = "Time",
    y = "Survival probability",
    color = "Risk quartile",
    fill  = "Risk quartile"
  ) +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        panel.spacing.x = unit(0.8, "lines"))

```

The quartile panels show a clear risk gradient. Q4 (High) has the lowest survival and Q1 (Low) the highest, with gaps widening over time. Log ratio transforms separate best, and TSS is weakest.


# Comparing Más-o-menos scoring with the LRA model

To explore alternative strategies for risk prediction, we implemented the [Más-o-menos method](https://academic.oup.com/bioinformatics/article/30/21/3062/2422201) (Armañanzas et al., 2014), a simple sign-based approach that averages the direction of effect from univariate Cox models. Each feature contributes either positively or negatively based on the sign of its estimated coefficient, and the overall risk score is calculated as the mean of these directional contributions.

We compared this score against the log-ratio-based (LRA) Cox models (normal and horseshoe), which had previously shown the best predictive performance among the tested transformations. Both methods were evaluated on the same set of top-ranked microbial features, and their predicted risk scores were compared in relation to observed event outcomes.

```{r}
# LRA, normal prior
pred_normal <- posterior_linpred(fit_lra_normal, transform = FALSE)
df_lra_normal <- df_lra
df_lra_normal$risk_score <- apply(pred_normal, 2, median)
df_lra_normal$method <- "LRA – Normal"

# LRA, horseshoe prior
pred_hs <- posterior_linpred(fit_lra_hs, transform = FALSE)
df_lra_hs <- df_lra
df_lra_hs$risk_score <- apply(pred_hs, 2, median)
df_lra_hs$method <- "LRA – Horseshoe"

# Más-o-menos
df_masomenos <- df_lra
df_masomenos$risk_score <- calculate_masomenos(df_masomenos)
df_masomenos$method <- "Más-o-menos"

df_all <- rbind(
  df_lra_normal[, c("risk_score", "Event", "method")],
  df_lra_hs[, c("risk_score", "Event", "method")],
  df_masomenos[, c("risk_score", "Event", "method")]
)

ggplot(df_all, aes(x = factor(Event), y = risk_score, fill = method)) +
  geom_boxplot(position = position_dodge(width = 0.75)) +
  scale_fill_manual(values = c(
    "LRA – Normal"    = "#1f78b4",
    "LRA – Horseshoe" = "#33a02c",
    "Más-o-menos"     = "#e31a1c"
  )) +
  labs(
    title = "Predicted Risk Scores by Event Status",
    x = "Event (0 = censored, 1 = occurred)",
    y = "Risk Score",
    fill = "Method"
  ) +
  theme_minimal(base_size = 14)

```

The figure indicates that all three methods produce higher predicted risk scores for individuals who experienced the event compared to those who were censored, showing that they capture the expected risk–outcome relationship reasonably well. The separation between groups is visible for each method, but given the degree of overlap in score distributions, no firm conclusions can be drawn about differences in performance between the methods based on this plot alone.



# Comparing different survival models across transformations (Updated)


We compare seven survival models: Cox proportional hazards model, logistic regression, Random Survival Forests, XGBoost, DeepSurv, CatBoost, and TabPFN. To ensure a fair comparison, we evaluate all available taxonomy/feature-coding schemes and apply the same choice across methods. Transformations and models are evaluated with 5-fold cross-validation using Harrell’s C-index as the primary metric. For computational reasons, the Cox model is implemented in a frequentist rather than Bayesian form.


```{r, include=FALSE}
out_dir <- file.path("model_result", "results")
CV_SEED <- 1
K_FOLDS <- 5
set.seed(CV_SEED)
tag <- paste0("cv", K_FOLDS)
cox   <- readRDS(file.path(out_dir, "coxph_cindex_cv5_summary.rds"))
rsf   <- readRDS(file.path(out_dir, "rsf_cindex_cv5_summary.rds"))
xgb   <- readRDS(file.path(out_dir, "xgb_cindex_cv5_summary.rds"))
deep  <- readRDS(file.path(out_dir, "deepsurv_cindex_cv5_summary.rds"))
logit <- readRDS(file.path(out_dir, "logit_cindex_cv5_summary.rds"))
cb    <- readRDS(file.path(out_dir, "catboost_bin_cindex_cv5_summary.rds"))
tab   <- readRDS(file.path(out_dir, "tabpfn_bin_cindex_cv5_summary.rds"))
```

```{r}
# Combine all models
combined_metrics <- bind_rows(cox, rsf, xgb, deep, logit, cb, tab)
```


```{r, fig.width=10, fig.height=6, dpi=300}
# Method label order
method_levels <- c(
  "CoxPH_5CV",
  "RSF_5CV",
  "XGB_Cox_5CV",
  "DeepSurv_5CV",
  "Logit_Binomial_5CV",
  "CatBoost_Binomial_5CV",
  "TabPFN_Binomial_5CV"
)

cindex_metrics <- combined_metrics %>%
  dplyr::filter(metric == "C") %>%
  dplyr::mutate(method = as.character(method))

present <- intersect(method_levels, unique(cindex_metrics$method))
others  <- setdiff(unique(cindex_metrics$method), present)
method_levels_use <- c(present, others)

cindex_metrics <- cindex_metrics %>%
  dplyr::mutate(method = factor(method, levels = method_levels_use))

# Ordering
top_methods <- c("CatBoost_Binomial_5CV", "TabPFN_Binomial_5CV", "RSF_5CV")

order_df <- cindex_metrics %>%
  dplyr::filter(method %in% top_methods) %>%
  dplyr::group_by(model) %>%
  dplyr::summarise(score = mean(estimate, na.rm = TRUE), .groups = "drop") %>%
  dplyr::arrange(dplyr::desc(score))

model_order <- order_df$model
cindex_metrics$model <- factor(cindex_metrics$model, levels = model_order)

# Plot 
ggplot(cindex_metrics, aes(x = model, y = estimate, color = method)) +
  geom_point(size = 4, stroke = 1.1,
             position = position_dodge(width = 0.7), na.rm = TRUE) +
  geom_errorbar(aes(ymin = lower, ymax = upper),
                width = 0.15, size = 1,
                position = position_dodge(width = 0.7), na.rm = TRUE) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  labs(
    title = "C-index: CoxPH, RSF, XGB-Cox, DeepSurv, Logit, CatBoost, TabPFN",
    x = "Transformation",
    y = "Harrell's C",
    color = "Method"
  ) +
  coord_cartesian(ylim = c(0.45, 1.00)) +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text.x = element_text(angle = 20, hjust = 1)
  )

```



CatBoost and TabPFN perform best overall. Treating survival as a binomial event probability fits this dataset better than proportional hazards. Cox and logistic models struggle, especially on LRA where the feature count is very high. XGBoost with the Cox objective performs worse than RSF mainly because the Cox loss doesn’t suit this dataset. RSF doesn’t rely on that assumption and handles many correlated features and interactions well. Among transformations, LRA, rCLR, and CLR give the strongest results.

For each transformation, we train a CatBoost model with K-fold CV and use the out-of-fold predicted event probability as the risk score. Within each transformation, individuals are split at the transformation-specific median into Low vs High risk. The panels show Kaplan–Meier curves with 95% CIs for each transformation. 

```{r, fig.width=10, fig.height=6, dpi=300}
# Read rds
cat_risks <- readRDS(file.path(out_dir, paste0("catboost_oof_risks_", tag, ".rds")))

# Median split per transform (High vs Low risk)
cat_risks <- cat_risks %>%
  group_by(Method) %>%
  mutate(
    RiskGroup = if_else(risk_score >= median(risk_score, na.rm = TRUE), "High", "Low"),
    RiskGroup = factor(RiskGroup, levels = c("Low","High"))
  ) %>%
  ungroup()

# Kaplan–Meier curves per transform
km_df <- cat_risks %>%
  group_split(Method) %>%
  map_dfr(function(d){
    meth <- as.character(d$Method[1])
    sf <- survfit(Surv(Event_time, Event) ~ RiskGroup, data = d,
                  conf.int = 0.95, conf.type = "log-log")
    survminer::surv_summary(sf, data = d) %>%
      mutate(Method = meth, RiskGroup = sub("^RiskGroup=", "", strata)) %>%
      select(Method, time, surv, lower, upper, RiskGroup)
  })

# Plot
ggplot(km_df, aes(x = time, y = surv, color = RiskGroup, fill = RiskGroup)) +
  geom_step(linewidth = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, color = NA) +
  facet_wrap(~ Method, ncol = 4) +
  labs(
    title = "Kaplan–Meier by median risk, CatBoost per transformation",
    x = "Time",
    y = "Survival probability",
    color = "Risk group",
    fill  = "Risk group"
  ) +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        panel.spacing.x = unit(0.8, "lines"))
```


